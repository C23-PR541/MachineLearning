{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "Import from drive"
      ],
      "metadata": {
        "id": "7_oUr-6rlh1O"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vVLd9UpglT5g",
        "outputId": "600d6b9e-61b8-47df-ce7c-ddb7fad84501"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive/\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive/', force_remount=True)\n",
        "#%cd /drive"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#pwd! #kita lg ada di mana "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "Tz6w-LPrlp4u",
        "outputId": "d8839624-a84b-41c7-f0d2-8ec7b87a28ea"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "'/drive'"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "\n",
        "base_dir = '/content/drive/MyDrive/exe_img'\n",
        "!ls \"/content/drive/MyDrive/exe_img\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MboiHjCwZfGf",
        "outputId": "43f93162-e16e-4923-b221-0ddf95fdf46c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "bahan  train  validation\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf"
      ],
      "metadata": {
        "id": "EHfPf8M4r09R"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menentukan direktori\n",
        "\n",
        "bahan_dir = os.path.join(base_dir, 'bahan')\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ],
      "metadata": {
        "id": "66192gnEZe91"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Menetukan direktori isi bahan\n",
        "\n",
        "hammer_dir = os.path.join(bahan_dir, 'hammer_curl/')\n",
        "barbell_dir = os.path.join(bahan_dir, 'barbell_curl/')\n",
        "chestfly_dir = os.path.join(bahan_dir, 'chest_fly_machine/')\n",
        "deadlift_dir = os.path.join(bahan_dir, 'deadlift/')\n",
        "pulldown_dir = os.path.join(bahan_dir, 'lat_pulldown/')\n",
        "extension_dir = os.path.join(bahan_dir, 'leg_extension/')\n",
        "\n",
        "print(\"Jumlah Data Train Tiap Kelas\")\n",
        "print(\"Jumlah gambar hammer : \", len(os.listdir(hammer_dir)))\n",
        "print(\"Jumlah gambar barbel : \", len(os.listdir(barbell_dir)))\n",
        "print(\"Jumlah gambar chest fly machine : \", len(os.listdir(chestfly_dir)))\n",
        "print(\"Jumlah gambar deadlift : \", len(os.listdir(deadlift_dir)))\n",
        "print(\"Jumlah gambar lat_pulldown : \", len(os.listdir(pulldown_dir)))\n",
        "print(\"Jumlah gambar leg extension : \", len(os.listdir(extension_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Sieau2k9iEGl",
        "outputId": "f8baaee6-03a0-4a35-b312-6bfcabe3c076"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah Data Train Tiap Kelas\n",
            "Jumlah gambar hammer :  546\n",
            "Jumlah gambar barbel :  705\n",
            "Jumlah gambar chest fly machine :  527\n",
            "Jumlah gambar deadlift :  530\n",
            "Jumlah gambar lat_pulldown :  646\n",
            "Jumlah gambar leg extension :  586\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Directori isi training\n",
        "\n",
        "hammer_dir = os.path.join(train_dir, 'hammer_curl/')\n",
        "barbell_dir = os.path.join(train_dir, 'barbell_curl/')\n",
        "chestfly_dir = os.path.join(train_dir, 'chest_fly_machine/')\n",
        "deadlift_dir = os.path.join(train_dir, 'deadlift/')\n",
        "pulldown_dir = os.path.join(train_dir, 'lat_pulldown/')\n",
        "extension_dir = os.path.join(train_dir, 'leg_extension/')\n",
        "\n",
        "# Directori isi validation\n",
        "hammer_dir = os.path.join(validation_dir, 'hammer_curl/')\n",
        "barbell_dir = os.path.join(validation_dir, 'barbell_curl/')\n",
        "chestfly_dir = os.path.join(validation_dir, 'chest_fly_machine/')\n",
        "deadlift_dir = os.path.join(validation_dir, 'deadlift/')\n",
        "pulldown_dir = os.path.join(validation_dir, 'lat_pulldown/')\n",
        "extension_dir = os.path.join(validation_dir, 'leg_extension/')"
      ],
      "metadata": {
        "id": "LFL8DqoDj-g7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Menyiapkan dataset"
      ],
      "metadata": {
        "id": "k5LTIjBIkfm8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import random\n",
        "from shutil import copyfile\n",
        "\n",
        "def train_val_split(source, train, val, train_ratio):\n",
        "  total_size = len(os.listdir(source))\n",
        "  train_size = int(train_ratio * total_size)\n",
        "  val_size = total_size - train_size\n",
        "\n",
        "  randomized = random.sample(os.listdir(source), total_size)\n",
        "  train_files = randomized[0:train_size]\n",
        "  val_files = randomized[train_size:total_size]\n",
        "\n",
        "  for i in train_files:\n",
        "    i_file = str(source + 1)\n",
        "    destination = train +1\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "  for i in val_files:\n",
        "    i_file = source + 1\n",
        "    destination = train +1\n",
        "    copyfile(i_file, destination)\n",
        "\n",
        "# Jumlah pembagian data training dan testing\n",
        "train_ratio = 0.8\n",
        "\n",
        "#Pembagian training dan Validasi\n",
        "#training\n",
        "source_00 = hammer_dir\n",
        "source_00 = barbell_dir\n",
        "source_00 = chestfly_dir \n",
        "\n",
        "train_00 = hammer_dir\n",
        "train_00 = barbell_dir\n",
        "train_00 = chestfly_dir \n",
        "\n",
        "val_00 = hammer_dir\n",
        "val_00 = barbell_dir\n",
        "val_00 = chestfly_dir\n",
        "\n",
        "train_val_split(source_00, train_00, val_00, train_ratio)\n",
        "\n",
        "# Validation\n",
        "source_01 = deadlift_dir\n",
        "source_01 = pulldown_dir\n",
        "source_01 = extension_dir \n",
        "\n",
        "train_01 = deadlift_dir\n",
        "train_01 = pulldown_dir\n",
        "train_01 = extension_dir \n",
        "\n",
        "val_01 = deadlift_dir\n",
        "val_01 = pulldown_dir\n",
        "val_01 = extension_dir \n",
        "\n",
        "train_val_split(source_01, train_01, val_00, train_ratio)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "T5a3kAalkecv",
        "outputId": "726bf0d7-7546-4f2b-87ec-4a2bcf81c08f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-7-cf2b68e94239>\u001b[0m in \u001b[0;36m<cell line: 40>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[0mval_00\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchestfly_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     39\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 40\u001b[0;31m \u001b[0mtrain_val_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_00\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_ratio\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     41\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     42\u001b[0m \u001b[0;31m# Validation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-7-cf2b68e94239>\u001b[0m in \u001b[0;36mtrain_val_split\u001b[0;34m(source, train, val, train_ratio)\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtrain_files\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 14\u001b[0;31m     \u001b[0mi_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msource\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     15\u001b[0m     \u001b[0mdestination\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain\u001b[0m \u001b[0;34m+\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     16\u001b[0m     \u001b[0mcopyfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mi_file\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdestination\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: can only concatenate str (not \"int\") to str"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"Jumlah gambar barbel : \", len(os.listdir(barbell_dir)))\n",
        "print(\"Jumlah train barbel : \", len(os.listdir(train_barbell)))\n",
        "print(\"Jumlah validation barbel : \", len(os.listdir(barbell_dir)))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 217
        },
        "id": "B3l4agL5paW4",
        "outputId": "06c071aa-3f1b-451a-d00f-9809039f11a0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Jumlah gambar barbel :  704\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-34728ea9dbaa>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jumlah gambar barbel : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbarbell_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jumlah train barbel : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_barbell\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Jumlah validation barbel : \"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlistdir\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbarbell_dir\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_barbell' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Pre processing"
      ],
      "metadata": {
        "id": "GoMpk1B-rLXK"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
      ],
      "metadata": {
        "id": "i2I3_AEprKhp"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.3,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.2,\n",
        "    zoom_range = 0.1\n",
        ")\n",
        "\n",
        "val_datagen = ImageDataGenerator(\n",
        "    rescale = 1./255,\n",
        "    rotation_range = 30,\n",
        "    horizontal_flip = True,\n",
        "    shear_range = 0.3,\n",
        "    fill_mode = 'nearest',\n",
        "    width_shift_range = 0.2,\n",
        "    height_shift_range = 0.2,\n",
        "    zoom_range = 0.1\n",
        ")"
      ],
      "metadata": {
        "id": "feQaZ5MKsdq7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Target"
      ],
      "metadata": {
        "id": "ZYAyV03s86cA"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "train_generator = train_datagen.flow_from_directory(\n",
        "    train_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")\n",
        "\n",
        "val_generator = val_datagen.flow_from_directory(\n",
        "    validation_dir,\n",
        "    target_size = (150, 150),\n",
        "    batch_size = 10,\n",
        "    class_mode = 'categorical'\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "llvO7ly28QwK",
        "outputId": "5d5dee4a-0b06-44e7-ac14-e1a41cad24c9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Found 0 images belonging to 7 classes.\n",
            "Found 0 images belonging to 7 classes.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "class myCallback(tf.keras.callbacks.Callback):\n",
        "  def on_epoch_end(self, epoch, logs = ()):\n",
        "    if(logs.get('accuracy') > 0.50):\n",
        "      print('\\nAkurasi mencapai 50%')\n",
        "      self.model.stop_training = True\n",
        "    \n",
        "\n",
        "callbacks = myCallback()"
      ],
      "metadata": {
        "id": "enw12ni39KRX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model CNN"
      ],
      "metadata": {
        "id": "tH05VR1N964W"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.layers.serialization import activation\n",
        "model = tf.keras.models.Sequential([\n",
        "    tf.keras.layers.Conv2D(16, (3,3), activation = 'relu', input_shape = (150, 150, 3)),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(32, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Conv2D(64, (3,3), activation = 'relu'),\n",
        "    tf.keras.layers.MaxPooling2D(2, 2),\n",
        "    tf.keras.layers.Flatten(),\n",
        "    tf.keras.layers.Dense(200, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.3, seed=112),\n",
        "    tf.keras.layers.Dense(500, activation = 'relu'),\n",
        "    tf.keras.layers.Dropout(0.5, seed=112),\n",
        "    tf.keras.layers.Dense(200, activation = 'relu'),\n",
        "    tf.keras.layers.Dense(2, activation = 'sigmoid')\n",
        "])"
      ],
      "metadata": {
        "id": "R5CWgq8u9785"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "svGNo6Rl9576",
        "outputId": "12412b7d-4779-4668-a880-795058ab09b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " conv2d_3 (Conv2D)           (None, 148, 148, 16)      448       \n",
            "                                                                 \n",
            " max_pooling2d_3 (MaxPooling  (None, 74, 74, 16)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_4 (Conv2D)           (None, 72, 72, 32)        4640      \n",
            "                                                                 \n",
            " max_pooling2d_4 (MaxPooling  (None, 36, 36, 32)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " conv2d_5 (Conv2D)           (None, 34, 34, 64)        18496     \n",
            "                                                                 \n",
            " max_pooling2d_5 (MaxPooling  (None, 17, 17, 64)       0         \n",
            " 2D)                                                             \n",
            "                                                                 \n",
            " flatten_1 (Flatten)         (None, 18496)             0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 200)               3699400   \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 200)               0         \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 500)               100500    \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 500)               0         \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 200)               100200    \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 402       \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 3,924,086\n",
            "Trainable params: 3,924,086\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(\n",
        "    loss = 'categorical_crossentropy',\n",
        "    optimizer = 'Adam',\n",
        "    metrics = ['accuracy']\n",
        ")"
      ],
      "metadata": {
        "id": "6-gvo8ic_uNf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(\n",
        "    train_generator,\n",
        "    steps_per_epoch = 7,\n",
        "    epoch = 25,\n",
        "    validation_data = val_generator,\n",
        "    validation_steps = 1,\n",
        "    verbose = 1,\n",
        "    callback =[callbacks]\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 380
        },
        "id": "fbJw-J8YAF4C",
        "outputId": "75228fb7-62af-49d8-cb83-dbe66792fbf8"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "TypeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-20-6114f53cb3fc>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m history = model.fit(\n\u001b[0m\u001b[1;32m      2\u001b[0m     \u001b[0mtrain_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m     \u001b[0msteps_per_epoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m7\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m     \u001b[0mepoch\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0mvalidation_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_generator\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     68\u001b[0m             \u001b[0;31m# To get the full stack trace, call:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     69\u001b[0m             \u001b[0;31m# `tf.debugging.disable_traceback_filtering()`\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 70\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     71\u001b[0m         \u001b[0;32mfinally\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     72\u001b[0m             \u001b[0;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/keras/utils/traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     63\u001b[0m         \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 65\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     66\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     67\u001b[0m             \u001b[0mfiltered_tb\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mTypeError\u001b[0m: Model.fit() got an unexpected keyword argument 'epoch'"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Tingkat Akurasi"
      ],
      "metadata": {
        "id": "zq_P6q9rAhTW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "%matplotlib inline\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.image as mpimg\n",
        "\n",
        "acc = history.history['accuracy']\n",
        "val_acc = history.history['val_accuracy']\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "\n",
        "epoch = range(len(acc))\n",
        "\n",
        "plt.plot(epoch, acc, 'r', label = 'Training Accuracy')\n",
        "plt.plot(epoch, val, 'b', label = 'Validation Accuracy')\n",
        "plt.title('Training and Validation accuracy')\n",
        "plt.legend(loc = 'best')\n",
        "plt.show()"
      ],
      "metadata": {
        "id": "F-1rtyPEAgvJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Klasifikasi"
      ],
      "metadata": {
        "id": "H06bU-wSB-5X"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "from keras.preprocessing import image\n",
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "\n",
        "  #predicting images\n",
        "  path = fn\n",
        "  img = iamge.load_img(path, target_size = (150, 150))\n",
        "  imgplot = plt.imgshow(img)\n",
        "  x = image.img_to_array(img)\n",
        "  x = np.expand_dims(x, axis = 0)\n",
        "\n",
        "  images = np.vstack([x])\n",
        "  clases = model.predict(images, batch_size = 100)\n",
        "\n",
        "  print(fn)\n",
        "\n",
        "  class_list = os.listdir(train_dir)\n",
        "\n",
        "  for j in range(42):\n",
        "    if classes[0][j] == 1. :\n",
        "      print('This imagebelongsto class', class_list[j-1])\n",
        "      break\n"
      ],
      "metadata": {
        "id": "7FKlcR7WCBGT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import glob\n",
        "import zipfile\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split"
      ],
      "metadata": {
        "id": "lXMX75yime4D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hammer_curl = glob.glob('MyDrive/Exercise Images/hammer curl/*.*')\n",
        "barbell_curl = glob.glob('MyDrive/Exercise Images/barbell biceps curl/*.*')\n",
        "chest_fly_machine = glob.glob('MyDrive/Exercise Images/chest fly machine/*.*')\n",
        "deadlift = glob.glob('MyDrive/Exercise Images/deadlift/*.*')\n",
        "lat_pulldown = glob.glob('MyDrive/Exercise Images/lat pulldown/*.*')\n",
        "leg_extension = glob.glob('MyDrive/Exercise Images/leg extension/*.*')\n",
        "shoulder_press = glob.glob('MyDrive/Exercise Images/shoulder press/*.*')"
      ],
      "metadata": {
        "id": "bLt5VsoGnGCj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data = []\n",
        "labels = []"
      ],
      "metadata": {
        "id": "PsTeufimRQro"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i in hammer_curl:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(0)\n",
        "\n",
        "for i in barbell_curl:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(1)\n",
        "\n",
        "for i in chest_fly_machine:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(2)\n",
        "\n",
        "for i in deadlift:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(3)\n",
        "  \n",
        "for i in lat_pulldown:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(4)\n",
        "\n",
        "for i in leg_extension:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(5)\n",
        "\n",
        "for i in shoulder_press:   \n",
        "    image=tf.keras.preprocessing.image.load_img(i, color_mode='rgb', \n",
        "    target_size= (150,150))\n",
        "    image=np.array(image)\n",
        "    data.append(image)\n",
        "    labels.append(6)"
      ],
      "metadata": {
        "id": "_m04_H48RSK8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dropout, Dense, Flatten\n",
        "from keras.optimizers import SGD\n",
        "from keras.layers.convolutional import Conv2D, MaxPooling2D\n",
        "from keras.utils import np_utils as u"
      ],
      "metadata": {
        "id": "nc6-FPwEDGix"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "\n",
        "# All images will be rescaled by 1./255.\n",
        "train_datagen = ImageDataGenerator( rescale = 1.0/255. )\n",
        "test_datagen  = ImageDataGenerator( rescale = 1.0/255. )\n",
        "\n",
        "# --------------------\n",
        "# Flow training images in batches of 20 using train_datagen generator\n",
        "# --------------------\n",
        "train_generator = train_datagen.flow_from_directory(train_dir,\n",
        "                                                    batch_size=20,\n",
        "                                                    class_mode='binary',\n",
        "                                                    target_size=(150, 150))     \n",
        "# --------------------\n",
        "# Flow validation images in batches of 20 using test_datagen generator\n",
        "# --------------------\n",
        "validation_generator =  test_datagen.flow_from_directory(validation_dir,\n",
        "                                                         batch_size=20,\n",
        "                                                         class_mode  = 'binary',\n",
        "                                                         target_size = (150, 150))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "tWHWEQj-2zi4",
        "outputId": "5c744fec-b3bb-4c07-b9cd-eae9c4c449dc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-12-1f54f7af94c6>\u001b[0m in \u001b[0;36m<cell line: 10>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[0;31m# Flow training images in batches of 20 using train_datagen generator\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m \u001b[0;31m# --------------------\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 10\u001b[0;31m train_generator = train_datagen.flow_from_directory(train_dir,\n\u001b[0m\u001b[1;32m     11\u001b[0m                                                     \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m20\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m                                                     \u001b[0mclass_mode\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'binary'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_dir' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data = np.array(data)\n",
        "labels = np.array(labels)"
      ],
      "metadata": {
        "id": "cjTizXh9Rwj2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train, X_test, ytrain, ytest = train_test_split(data, labels, test_size=0.2,\n",
        "                                                random_state=42)"
      ],
      "metadata": {
        "id": "cHgjSayIRxO6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "(X, y), (X_test, y_test) = Exercise Images.load_data()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 130
        },
        "id": "pzIEuwzEDUXb",
        "outputId": "5c6eab51-208e-4917-f4b6-cfc3c2327998"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "SyntaxError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-17-7be80429c4b6>\"\u001b[0;36m, line \u001b[0;32m1\u001b[0m\n\u001b[0;31m    (X, y), (X_test, y_test) = Exercise Images.load_data()\u001b[0m\n\u001b[0m                                        ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def create_model():\n",
        "  # DEFINE A KERAS MODEL TO CLASSIFY CATS V DOGS\n",
        "  # USE AT LEAST 3 CONVOLUTION LAYERS\n",
        "\n",
        "  ### START CODE HERE\n",
        "\n",
        "  model = tf.keras.models.Sequential([ \n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\", input_shape=(150, 150, 3)),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Conv2D(64, (3, 3), activation=\"relu\"),\n",
        "      tf.keras.layers.MaxPooling2D(2, 2),\n",
        "      tf.keras.layers.Flatten(),\n",
        "      tf.keras.layers.Dense(512, activation=\"relu\"),\n",
        "      tf.keras.layers.Dense(1, activation=\"sigmoid\")\n",
        "  ])\n",
        "\n",
        "  \n",
        "  model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001),\n",
        "                loss=\"binary_crossentropy\",\n",
        "                metrics=['accuracy']) \n",
        "    \n",
        "  ### END CODE HERE\n",
        "\n",
        "  return model"
      ],
      "metadata": {
        "id": "v1cZathYUwNn"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer='adam', loss='categorical_crossentropy', metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "QiNOqPRNrn3i",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 165
        },
        "outputId": "bcc072e3-821a-4e0e-f674-6b04eb011b03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-11-228481410b08>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcompile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'adam'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m'categorical_crossentropy'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmetrics\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'accuracy'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m: name 'model' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(data, labels, epochs=10, validation_data=(data, labels))"
      ],
      "metadata": {
        "id": "Iq2DRsJurpYA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(data, labels)\n",
        "print('Test loss:', test_loss)\n",
        "print('Test accuracy:', test_accuracy)"
      ],
      "metadata": {
        "id": "L0Dcr6BTsgy8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get the untrained model\n",
        "model = create_model()\n",
        "\n",
        "# Train the model\n",
        "# Note that this may take some time.\n",
        "history = model.fit(train_generator,\n",
        "                    epochs=15,\n",
        "                    verbose=1,\n",
        "                    validation_data=validation_generator)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 235
        },
        "id": "hk3VVos3Y-5s",
        "outputId": "c7a8b477-b489-4804-c52a-756c4bccb5a4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "NameError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-15-4fd84b04e1cf>\u001b[0m in \u001b[0;36m<cell line: 6>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Train the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;31m# Note that this may take some time.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m history = model.fit(train_generator,\n\u001b[0m\u001b[1;32m      7\u001b[0m                     \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m15\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m                     \u001b[0mverbose\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mNameError\u001b[0m: name 'train_generator' is not defined"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget --no-check-certificate https://www.kaggle.com/datasets/hasyimabdillah/workoutexercises-images"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "67FNtuBrIz1u",
        "outputId": "cb029bad-c55e-4f26-f8f3-a41114677d03"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2023-05-26 13:06:27--  https://www.kaggle.com/datasets/hasyimabdillah/workoutexercises-images\n",
            "Resolving www.kaggle.com (www.kaggle.com)... 35.244.233.98\n",
            "Connecting to www.kaggle.com (www.kaggle.com)|35.244.233.98|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: unspecified [text/html]\n",
            "workoutexercises-images: Operation not supported\n",
            "\n",
            "Cannot write to ‘workoutexercises-images’ (Success).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import zipfile\n",
        "\n",
        "# Unzip the archive\n",
        "local_zip = './Exercise Images.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall()\n",
        "\n",
        "zip_ref.close()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "qLD3MiBlK4DT",
        "outputId": "7cffb2e0-6328-4fd1-fbc2-962c5587f241"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-495f143c51bc>\u001b[0m in \u001b[0;36m<cell line: 5>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Unzip the archive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mlocal_zip\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'./Exercise Images.zip'\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mzip_ref\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mzipfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mZipFile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlocal_zip\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'r'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0mzip_ref\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextractall\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/lib/python3.10/zipfile.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, file, mode, compression, allowZip64, compresslevel, strict_timestamps)\u001b[0m\n\u001b[1;32m   1249\u001b[0m             \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1250\u001b[0m                 \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1251\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfp\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mio\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfilemode\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1252\u001b[0m                 \u001b[0;32mexcept\u001b[0m \u001b[0mOSError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1253\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mfilemode\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmodeDict\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: './Exercise Images.zip'"
          ]
        }
      ]
    }
  ]
}